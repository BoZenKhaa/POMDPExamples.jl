{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPPolicies\n",
    "using POMDPs\n",
    "using BeliefUpdaters\n",
    "using POMDPModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct HeuristicPolicy{P<:POMDP, A} <: Policy\n",
    "    pomdp::P\n",
    "    action_map::Vector{A}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeuristicPolicy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function HeuristicPolicy(pomdp::POMDP)\n",
    "    HeuristicPolicy(pomdp, actions(pomdp))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: pomdp not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pomdp not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[4]:1"
     ]
    }
   ],
   "source": [
    "DiscreteUpdater(pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function action(p::HeuristicPolicy, b::DiscreteBelief)\n",
    "    max_value = -Inf\n",
    "    best_idx = 1\n",
    "    for i = 1:n_actions(p.pomdp)\n",
    "        a = p.action_map[i]\n",
    "        action_val = 0.0\n",
    "        for (bel,state) in zip(b.b, b.state_list)\n",
    "            action_val += bel*reward(p.pomdp, state, a)\n",
    "        end\n",
    "        \n",
    "        if action_val > max_value\n",
    "            best_idx = i\n",
    "            max_value = action_val\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return p.action_map[best_idx]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TigerPOMDP(-1.0, -100.0, 10.0, 0.85, 0.95)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pomdp = TigerPOMDP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeuristicPolicy{TigerPOMDP,Int64}(TigerPOMDP(-1.0, -100.0, 10.0, 0.85, 0.95), [0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heur_pol = HeuristicPolicy(pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching action(::HeuristicPolicy{TigerPOMDP,Int64}, ::DiscreteBelief{TigerPOMDP,Bool})\nClosest candidates are:\n  action(!Matched::CategoricalTabularPolicy, ::Any) at /home/shushman/.julia/packages/POMDPPolicies/oW6ud/src/stochastic.jl:30\n  action(!Matched::EpsGreedyPolicy, ::Any) at /home/shushman/.julia/packages/POMDPPolicies/oW6ud/src/stochastic.jl:45\n  action(!Matched::FeedWhenCrying, ::Any) at /home/shushman/.julia/packages/POMDPModels/dUyB8/src/CryingBabies.jl:81\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching action(::HeuristicPolicy{TigerPOMDP,Int64}, ::DiscreteBelief{TigerPOMDP,Bool})\nClosest candidates are:\n  action(!Matched::CategoricalTabularPolicy, ::Any) at /home/shushman/.julia/packages/POMDPPolicies/oW6ud/src/stochastic.jl:30\n  action(!Matched::EpsGreedyPolicy, ::Any) at /home/shushman/.julia/packages/POMDPPolicies/oW6ud/src/stochastic.jl:45\n  action(!Matched::FeedWhenCrying, ::Any) at /home/shushman/.julia/packages/POMDPModels/dUyB8/src/CryingBabies.jl:81\n  ...",
      "",
      "Stacktrace:",
      " [1] simulate(::RolloutSimulator{Random.MersenneTwister}, ::TigerPOMDP, ::HeuristicPolicy{TigerPOMDP,Int64}, ::DiscreteUpdater{TigerPOMDP}, ::POMDPModelTools.BoolDistribution, ::Bool) at /home/shushman/.julia/packages/POMDPSimulators/xyfJM/src/rollout.jl:100",
      " [2] simulate at /home/shushman/.julia/packages/POMDPSimulators/xyfJM/src/rollout.jl:61 [inlined]",
      " [3] simulate(::RolloutSimulator{Random.MersenneTwister}, ::TigerPOMDP, ::HeuristicPolicy{TigerPOMDP,Int64}, ::DiscreteUpdater{TigerPOMDP}) at /home/shushman/.julia/packages/POMDPSimulators/xyfJM/src/rollout.jl:50",
      " [4] top-level scope at In[8]:3"
     ]
    }
   ],
   "source": [
    "using POMDPSimulators\n",
    "rollout_sim = RolloutSimulator(max_steps=10);\n",
    "history_fib = simulate(rollout_sim, pomdp, heur_pol, DiscreteUpdater(pomdp));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
